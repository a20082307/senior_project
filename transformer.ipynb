{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import math\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import shioaji as sj\n",
    "import talib as ta\n",
    "import torch\n",
    "import wandb\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper parameters and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyperparameters\n",
    "SEQ_LEN = 120\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 25\n",
    "D_MODEL = 6\n",
    "NUM_HEADS = 2\n",
    "NUM_ENCODER_LAYERS = 6\n",
    "DROPOUT_RATE = 0.1\n",
    "LEARNING_RATE = 1e-4\n",
    "K = 5\n",
    "\n",
    "## Parameters\n",
    "MIN_LATER = 15  # The minute we want to predict in the future\n",
    "DEVICE = (torch.cuda.is_available() and 'cuda:0') or 'cpu'\n",
    "\n",
    "BEGIN_TIME = datetime.time(9, 15)\n",
    "END_TIME = datetime.time(13, 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect with weight and bias website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrogerline0527\u001b[0m (\u001b[33mrogerline0527-national-tsing-hua-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.9 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\vscode\\python\\senior project\\wandb\\run-20240912_000152-bnao4q57</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/rogerline0527-national-tsing-hua-university/transformer/runs/bnao4q57' target=\"_blank\">rural-tree-65</a></strong> to <a href='https://wandb.ai/rogerline0527-national-tsing-hua-university/transformer' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/rogerline0527-national-tsing-hua-university/transformer' target=\"_blank\">https://wandb.ai/rogerline0527-national-tsing-hua-university/transformer</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/rogerline0527-national-tsing-hua-university/transformer/runs/bnao4q57' target=\"_blank\">https://wandb.ai/rogerline0527-national-tsing-hua-university/transformer/runs/bnao4q57</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/rogerline0527-national-tsing-hua-university/transformer/runs/bnao4q57?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x1fcdd639150>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(\n",
    "    project = \"transformer\",\n",
    "\n",
    "    config = {\n",
    "        \"architecture\": \"transformer\",\n",
    "        \"dataset\": \"TXF and TSMC\",\n",
    "        \"Kbar_timeunit\": \"15min\",\n",
    "        \"LOSS_FUNC\": \"MSE\",\n",
    "        \"OPTIMIZER\": \"adam\",\n",
    "\n",
    "        \"SEQ_LEN\": SEQ_LEN,\n",
    "        \"BATCH_SIZE\": BATCH_SIZE,\n",
    "        \"EPOCHS\": EPOCHS,\n",
    "        \"D_MODEL\": D_MODEL,\n",
    "        \"NUM_HEADS\": NUM_HEADS,\n",
    "        \"NUM_ENCODER_LAYERS\": NUM_ENCODER_LAYERS,\n",
    "        \"DROPOUT_RATE\": DROPOUT_RATE,\n",
    "        \"LEANING_RATE\": LEARNING_RATE,\n",
    "        \"KFold\": K,\n",
    "\n",
    "        \"MIN_LATER\": MIN_LATER,\n",
    "\n",
    "        \"EPSILON\": 1e-8,\n",
    "        \"BETA\": (0.9, 0.98),\n",
    "        \"WEIGHT_DECAY\": 0.02,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_plot(x_data: pd.DataFrame, y_data: pd.DataFrame, x_label: str, y_label: str) -> None:\n",
    "    fig = plt.figure(figsize=(7, 4))\n",
    "    plt.scatter(x_data, y_data, s = 1)\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indicators function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keltner_bands(close: np.ndarray, high: np.ndarray, low: np.ndarray, period: int, multiplier: int) -> tuple:\n",
    "    mid = ta.EMA(close, timeperiod = period)\n",
    "    mid = np.nan_to_num(mid, nan = mid.iloc[period - 1])\n",
    "    kelt_trange = np.array([])\n",
    "\n",
    "    for i in tqdm(range(1, len(close)), desc = \"Calculating kelner bands \"):\n",
    "        tem_trange = max(\n",
    "            high.iloc[-i] - low.iloc[-i],\n",
    "            abs(high.iloc[-i] - close.iloc[-i - 1]),\n",
    "            abs(low.iloc[-i] - close.iloc[-i - 1])\n",
    "        )\n",
    "        kelt_trange = np.append(tem_trange, kelt_trange)\n",
    "    kelt_trange = np.append(high.iloc[0] - low.iloc[0], kelt_trange)\n",
    "    atr = ta.EMA(kelt_trange, timeperiod = period)\n",
    "    atr = np.nan_to_num(atr, nan = atr[period - 1])\n",
    "    upper = mid + atr * multiplier\n",
    "    lower = mid - atr * multiplier\n",
    "\n",
    "    return upper, mid, lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KDJ(high: np.ndarray, low: np.ndarray, close: np.ndarray, period: int, signal_k: int, signal_d: int) -> tuple:\n",
    "    _alpha_k = 2 / (signal_k + 1)\n",
    "    _alpha_d = 2 / (signal_d + 1)\n",
    "\n",
    "    lowest = ta.MIN(low, timeperiod = period)\n",
    "    lowest = np.nan_to_num(lowest, nan = lowest.iloc[period - 1])\n",
    "    highest = ta.MAX(high, timeperiod = period)\n",
    "    highest = np.nan_to_num(highest, nan = highest.iloc[period - 1])\n",
    "\n",
    "    rsv = (close - lowest) / (highest - lowest) * 100\n",
    "    \n",
    "    K = np.array([50])\n",
    "    D = np.array([50])\n",
    "    J = np.array([50])\n",
    "    \n",
    "    for i in tqdm(range(1, len(close)), desc = \"Calculating KDJ \"):\n",
    "        K = np.append(K, int(_alpha_k * ((K[-1] + 2 * rsv.iloc[i]) / 3) + (1 - _alpha_k) * K[-1] + 0.5))\n",
    "        D = np.append(D,  int(_alpha_d * ((D[-1] + 2 * K[-1]) / 3) + (1 - _alpha_d) * D[-1] + 0.5))\n",
    "        J = np.append(J, 3 * K[-1] - 2 * D[-1])\n",
    "\n",
    "    return K, D, J"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data and split into train/test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succeed to load and check the data at 'data/TXF_long.csv'\n",
      "Succeed to load and check the data at 'data/TXFR1_1min.csv'\n"
     ]
    }
   ],
   "source": [
    "def load_and_check(data_path: str, start_date: datetime.date = None, end_date: datetime.date = None) -> pd.DataFrame:\n",
    "    global BEGIN_TIME, END_TIME\n",
    "\n",
    "    data = pd.read_csv(data_path, dtype = {\n",
    "        'Date': str,\n",
    "        'open': np.int16,\n",
    "        'high': np.int16,\n",
    "        'low': np.int16,\n",
    "        'close': np.int16,\n",
    "        'volume': np.int16\n",
    "    }, index_col = 0)\n",
    "    data.index = pd.to_datetime(data.Date)\n",
    "    data = data.between_time(BEGIN_TIME, END_TIME)\n",
    "\n",
    "    if start_date is not None:\n",
    "        data = data[(data.index.date >= start_date) & (data.index.date <= end_date)]\n",
    " \n",
    "    IS_MISSING_DATA = False\n",
    "    missing_time_index = []\n",
    "    for i in range(1, len(data.index)):\n",
    "        if data.index[i] - data.index[i - 1] != datetime.timedelta(minutes = 1) and data.index[i].time() != BEGIN_TIME:\n",
    "            if IS_MISSING_DATA == False:\n",
    "                IS_MISSING_DATA = True\n",
    "                print('Not continuous time: ')\n",
    "                \n",
    "            print('\\t', data.index[i - 1], data.index[i])\n",
    "            missing_time_index.append(i - 1)\n",
    "\n",
    "    finish = 0\n",
    "    if IS_MISSING_DATA:\n",
    "        print('=' * 50)\n",
    "\n",
    "        for int_index in missing_time_index:\n",
    "            time_delta = (data.index[int_index + finish + 1] - data.index[int_index + finish]).seconds // 60\n",
    "            Entity_delta = data.Open.iloc[int_index + finish + 1] - data.Close.iloc[int_index + finish]\n",
    "            High_delta = data.High.iloc[int_index + finish + 1] - data.High.iloc[int_index + finish]\n",
    "            Low_delta = data.Low.iloc[int_index + finish + 1] - data.Low.iloc[int_index + finish]\n",
    "            Volume_delta = data.Volume.iloc[int_index + finish + 1] - data.Volume.iloc[int_index + finish]\n",
    "            print(Entity_delta)\n",
    "\n",
    "            for minute in range(1, time_delta):\n",
    "                print(f\"Missing data at {data.index[int_index + finish]}\")\n",
    "                print(data.iloc[int_index + finish - 1: int_index + finish + 4][:-1], end = '\\n\\n')\n",
    "                \n",
    "                time_for_missing_data = (data.index[int_index + finish] + datetime.timedelta(minutes = 1))\n",
    "                new_data = pd.DataFrame({\n",
    "                    'Date': time_for_missing_data,\n",
    "                    'Open': data.Close.iloc[int_index + finish],\n",
    "                    'High': round(data.High.iloc[int_index + finish - minute + 1] + High_delta * minute / (time_delta - 1)),\n",
    "                    'Low': round(data.Low.iloc[int_index + finish - minute + 1] + Low_delta * minute / (time_delta - 1)),\n",
    "                    'Close': round(data.Close.iloc[int_index + finish - minute + 1] + Entity_delta * minute / (time_delta - 1)),\n",
    "                    'Volume': round(data.Volume.iloc[int_index + finish - minute + 1] + Volume_delta * minute / (time_delta - 1))\n",
    "                }, index = [time_for_missing_data])\n",
    "                data = pd.concat([data.iloc[:int_index + finish + 1], new_data, data.iloc[int_index + finish + 1:]])\n",
    "                finish += 1\n",
    "                print(data.iloc[int_index + finish - 1: int_index + finish + 4], end = '\\n\\n')\n",
    "\n",
    "        int_index_for_all_data = [i for i in range(len(data))]\n",
    "        data.insert(0, '', int_index_for_all_data)\n",
    "        data.to_csv(data_path, index = False)\n",
    "\n",
    "        load_and_check(data_path)\n",
    "    else:\n",
    "        print(f\"Succeed to load and check the data at '{data_path}'\")\n",
    "        return data\n",
    "\n",
    "TXF = load_and_check('data/TXF_long.csv')\n",
    "TXF_test = load_and_check('data/TXFR1_1min.csv', start_date = datetime.date(2023, 1, 1), end_date = datetime.date(2024, 8, 16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TXF shape: (761801, 6)\n",
      "TXF_test shape: (93749, 7)\n"
     ]
    }
   ],
   "source": [
    "print(f'TXF shape: {TXF.shape}')\n",
    "print(f'TXF_test shape: {TXF_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 609440\n",
      "valid size: 99341\n",
      "test size: 92785\n"
     ]
    }
   ],
   "source": [
    "## Split the data into training, validating and testing set\n",
    "TXF_train_and_valid = TXF[(TXF.index.date < datetime.date(2023, 1, 1))]\n",
    "TXF_train = TXF_train_and_valid.iloc[ : int(TXF.shape[0] * 0.8)]\n",
    "TXF_valid = TXF_train_and_valid.iloc[int(TXF.shape[0] * 0.8) : ]\n",
    "TXF_test = pd.concat([TXF[(TXF.index.date >= datetime.date(2023, 1, 1))], TXF_test[(TXF_test.index.date >= datetime.date(2023, 12, 9))]])\n",
    "\n",
    "print(f'train size: {TXF_train.shape[0]}')\n",
    "print(f'valid size: {TXF_valid.shape[0]}')\n",
    "print(f'test size: {TXF_test.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw_plot(TXF_train.index, TXF_train.Close, 'TXF Close', 'Time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating kelner bands : 100%|██████████| 708780/708780 [08:29<00:00, 1390.07it/s] \n"
     ]
    }
   ],
   "source": [
    "## Dataset and DataLoader\n",
    "class custom_dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, TXF, TSMC = None):\n",
    "        self.TXF = torch.cat((\n",
    "            torch.unsqueeze(torch.tensor(TXF.Open.values), 1),\n",
    "            torch.unsqueeze(torch.tensor(TXF.High.values), 1),\n",
    "            torch.unsqueeze(torch.tensor(TXF.Low.values), 1),\n",
    "            torch.unsqueeze(torch.tensor(TXF.Close.values), 1),\n",
    "            torch.unsqueeze(torch.tensor(TXF.Volume.values), 1)\n",
    "        ), 1)\n",
    "        # self.TSMC = torch.unsqueeze(torch.tensor(TSMC.Close.values), 1)\n",
    "        # print(self.TXF.shape)\n",
    "        # print(self.TSMC.shape)\n",
    "\n",
    "        self.TXF_close = torch.unsqueeze(torch.tensor(TXF.Close.values), 1).double()\n",
    "        # print(self.TXF_close.shape)\n",
    "\n",
    "        self.data_len = self.TXF.shape[0]\n",
    "\n",
    "        self.sma_short = ta.SMA(TXF.Close, timeperiod = 3)\n",
    "        self.sma_short = torch.tensor(np.nan_to_num(self.sma_short, nan = self.sma_short.iloc[2]))\n",
    "        self.sma_short = torch.unsqueeze(self.sma_short, 1)\n",
    "\n",
    "        self.sma_long = ta.SMA(TXF.Close, timeperiod = 9)\n",
    "        self.sma_long = torch.tensor(np.nan_to_num(self.sma_long, nan = self.sma_long.iloc[8]))\n",
    "        self.sma_long = torch.unsqueeze(self.sma_long, 1)\n",
    "\n",
    "        self.adosc = ta.ADOSC(TXF.High, TXF.Low, TXF.Close, TXF.Volume, fastperiod = 6, slowperiod = 15)\n",
    "        self.adosc = torch.tensor(np.nan_to_num(self.adosc, nan = self.adosc.iloc[14]))\n",
    "        self.adosc = torch.unsqueeze(self.adosc, 1)\n",
    "\n",
    "        self.bband_upper, self.bband_middle, self.bband_lower = ta.BBANDS(TXF.Close, timeperiod = 20, nbdevup = 2, nbdevdn = 2)\n",
    "\n",
    "        self.bband_upper = torch.tensor(np.nan_to_num(self.bband_upper, nan = self.bband_upper.iloc[19]))\n",
    "        self.bband_upper = torch.unsqueeze(self.bband_upper, 1)\n",
    "\n",
    "        self.bband_middle = torch.tensor(np.nan_to_num(self.bband_middle, nan = self.bband_middle.iloc[19]))\n",
    "        self.bband_middle = torch.unsqueeze(self.bband_middle, 1)\n",
    "\n",
    "        self.bband_lower = torch.tensor(np.nan_to_num(self.bband_lower, nan = self.bband_lower.iloc[19]))\n",
    "        self.bband_lower = torch.unsqueeze(self.bband_lower, 1)\n",
    "\n",
    "        self.keltner_upper, self.keltner_middle, self.keltner_lower = keltner_bands(TXF.Close, TXF.High, TXF.Low, 20, 1.5)\n",
    "        self.keltner_upper = torch.tensor(self.keltner_upper)\n",
    "        self.keltner_upper = torch.unsqueeze(self.keltner_upper, 1)\n",
    "\n",
    "        self.keltner_middle = torch.tensor(self.keltner_middle)\n",
    "        self.keltner_middle = torch.unsqueeze(self.keltner_middle, 1)\n",
    "\n",
    "        self.keltner_lower = torch.tensor(self.keltner_lower)\n",
    "        self.keltner_lower = torch.unsqueeze(self.keltner_lower, 1)\n",
    "\n",
    "        self.K, self.D, self.J = KDJ(TXF.High, TXF.Low, TXF.Close, 9, 3, 3)\n",
    "        self.K = torch.tensor(self.K)\n",
    "        self.K = torch.unsqueeze(self.K, 1)\n",
    "\n",
    "        self.D = torch.tensor(self.D)\n",
    "        self.D = torch.unsqueeze(self.D, 1)\n",
    "\n",
    "        self.J = torch.tensor(self.J)\n",
    "        self.J = torch.unsqueeze(self.J, 1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data_len - (SEQ_LEN + MIN_LATER + 1) - 1\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x_data = torch.cat((\n",
    "            self.TXF[idx : idx + SEQ_LEN],\n",
    "            # self.TSMC[idx : idx + SEQ_LEN],\n",
    "            self.sma_short[idx : idx + SEQ_LEN],\n",
    "            self.sma_long[idx : idx + SEQ_LEN],\n",
    "            self.adosc[idx : idx + SEQ_LEN],\n",
    "            self.bband_upper[idx : idx + SEQ_LEN],\n",
    "            self.bband_middle[idx : idx + SEQ_LEN],\n",
    "            self.bband_lower[idx : idx + SEQ_LEN],\n",
    "            self.keltner_upper[idx : idx + SEQ_LEN],\n",
    "            self.keltner_middle[idx : idx + SEQ_LEN],\n",
    "            self.keltner_lower[idx : idx + SEQ_LEN],\n",
    "            self.K[idx : idx + SEQ_LEN],\n",
    "            self.D[idx : idx + SEQ_LEN],\n",
    "            self.J[idx : idx + SEQ_LEN]\n",
    "        ), 1)\n",
    "\n",
    "        y_data = self.TXF_close[idx + SEQ_LEN + MIN_LATER + 1]\n",
    "\n",
    "        return x_data, y_data\n",
    "    \n",
    "train_valid_dataset = custom_dataset(TXF_train_and_valid)\n",
    "    \n",
    "# train_dataset = custom_dataset(TXF_train)\n",
    "# train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle = True, pin_memory = True, drop_last = True)\n",
    "\n",
    "# valid_dataset = custom_dataset(TXF_valid)\n",
    "# valid_dataloader = torch.utils.data.DataLoader(valid_dataset, batch_size = BATCH_SIZE, shuffle = True, pin_memory = True, drop_last = True)\n",
    "\n",
    "test_dataset = custom_dataset(TXF_test)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size = BATCH_SIZE, shuffle = True, pin_memory = True, drop_last = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In every data: \n",
      "\tx_data shape: torch.Size([120, 17])\n",
      "\ty_data shape: torch.Size([1])\n",
      "\n",
      "Which means we use the past [120] minutes data to predict the price in [15] minutes later\n"
     ]
    }
   ],
   "source": [
    "test = iter(torch.utils.data.DataLoader(test_dataset, batch_size = BATCH_SIZE, shuffle = False))\n",
    "# test = iter(torch.utils.data.DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle = False))\n",
    "test_x, test_y = next(test)\n",
    "FEATURE_NUM = test_x.shape[2]\n",
    "\n",
    "print(f'In every data: ')\n",
    "print(f'\\tx_data shape: {test_x[0].shape}')\n",
    "print(f'\\ty_data shape: {test_y[0].shape}\\n')\n",
    "print(f'Which means we use the past [{SEQ_LEN}] minutes data to predict the price in [{MIN_LATER}] minutes later')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 120, 17])\n",
      "torch.Size([32, 1])\n"
     ]
    }
   ],
   "source": [
    "print(test_x.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Position embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionEmbedding(torch.nn.Module):\n",
    "    def __init__(self, d_model: int) -> None:\n",
    "        super(PositionEmbedding, self).__init__()\n",
    "        self.linear = torch.nn.Linear(FEATURE_NUM, d_model, dtype = torch.double)\n",
    "\n",
    "        # Create a matrix of shape (max_len, feature_num)\n",
    "        pe = torch.zeros(SEQ_LEN, d_model)\n",
    "        position = torch.arange(0, SEQ_LEN, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        \n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        \n",
    "        pe = pe.unsqueeze(0)  # Add a batch dimension\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        x = x + self.pe[:, :x.size(1)]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi-head attention layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(torch.nn.Module):\n",
    "    def __init__(self, d_model: int, num_heads: int) -> None:\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        \n",
    "        # d_model should be divisible by num_heads\n",
    "        assert d_model % num_heads == 0\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.d_k = d_model // num_heads\n",
    "\n",
    "        self.V_linear = torch.nn.Linear(d_model, d_model, dtype = torch.double)\n",
    "        self.K_linear = torch.nn.Linear(d_model, d_model, dtype = torch.double)\n",
    "        self.Q_linear = torch.nn.Linear(d_model, d_model, dtype = torch.double)\n",
    "        self.output_linear = torch.nn.Linear(d_model, d_model, dtype = torch.double)\n",
    "\n",
    "    def scaled_dot_product_attention(self, Q: torch.tensor, K: torch.tensor, V: torch.tensor) -> torch.tensor:\n",
    "        # Q, V: [batch_size, num_heads, seq_len, d_k]\n",
    "        # K: [batch_size, num_heads, seq_len, d_k] -> K: [batch_size, num_heads, d_k, seq_len]\n",
    "        # attention: [batch_size, num_heads, seq_len, seq_len]\n",
    "        attention = torch.matmul(Q, K.transpose(-2, -1)) / torch.sqrt(torch.tensor(self.d_k).float())\n",
    "\n",
    "        # attention_prob: [batch_size, num_heads, seq_len, seq_len]\n",
    "        # It satisfies the sum of the last dimension is 1\n",
    "        # For example, assume the result of this softmax is a\n",
    "        # then a[0][0][0][0] + a[0][0][0][1] + ... + a[0][0][0][seq_len - 1] = 1\n",
    "        attention_prob = torch.nn.functional.softmax(attention, dim = -1)\n",
    "        output = torch.matmul(attention_prob, V)\n",
    "        return output\n",
    "    \n",
    "    def split_heads(self, x: torch.tensor) -> torch.tensor:\n",
    "        batch_size, seq_len, d_model = x.size()\n",
    "\n",
    "        # x: [batch_size, seq_len, d_model] -> x: [batch_size, num_heads, seq_len, d_k]\n",
    "        x = x.view(batch_size, seq_len, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        return x\n",
    "    \n",
    "    def concat_heads(self, x: torch.tensor) -> torch.tensor:\n",
    "        batch_size, _, seq_len, d_k = x.size()\n",
    "\n",
    "        # x: [batch_size, num_heads, seq_len, d_k] -> x: [batch_size, seq_len, d_model]\n",
    "        x = x.transpose(1, 2).contiguous().view(batch_size, seq_len, self.d_model)\n",
    "        return x\n",
    "    \n",
    "    def forward(self, Q: torch.tensor, K: torch.tensor, V: torch.tensor) -> torch.tensor:\n",
    "        Q = self.split_heads(self.Q_linear(Q))\n",
    "        K = self.split_heads(self.K_linear(K))\n",
    "        V = self.split_heads(self.V_linear(V))\n",
    "        # print(\"-> Split head succeeded!\")\n",
    "\n",
    "        attention_output = self.scaled_dot_product_attention(Q, K, V)\n",
    "        # print(\"-> Scaled dot product attention succeeded!\")\n",
    "\n",
    "        output = self.output_linear(self.concat_heads(attention_output))\n",
    "        # print(\"-> Concat head succeeded!\")\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feed forward layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(torch.nn.Module):\n",
    "    def __init__(self, d_model: int, d_ff: int) -> None:\n",
    "        super(FeedForward, self).__init__()\n",
    "        # self.fully_connected_1 = torch.nn.Linear(d_model, d_ff, dtype = torch.double)\n",
    "        # self.fully_connected_2 = torch.nn.Linear(d_ff, d_model, dtype = torch.double)\n",
    "        self.conv1d_1 = torch.nn.Conv1d(in_channels = d_model, out_channels = d_ff, kernel_size = 1, dtype = torch.double)\n",
    "        self.conv1d_2 = torch.nn.Conv1d(in_channels = d_ff, out_channels = d_model, kernel_size = 1, dtype = torch.double)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "    def forward(self, x: torch.tensor) -> torch.tensor:\n",
    "        x = x.transpose(1, 2)\n",
    "        nonliear_output_1 = self.relu(self.conv1d_1(x))\n",
    "        output = self.conv1d_2(nonliear_output_1)\n",
    "        return output.transpose(1, 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoder layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, d_model: int, num_heads: int, dropout_rate: int) -> None:\n",
    "        super(Encoder, self).__init__()\n",
    "        self.multi_head_attention = MultiHeadAttention(d_model, num_heads)\n",
    "        self.feed_forward = FeedForward(d_model, d_model * 4)\n",
    "        self.norm_1 = torch.nn.LayerNorm(d_model, dtype = torch.double)\n",
    "        self.norm_2 = torch.nn.LayerNorm(d_model, dtype = torch.double)\n",
    "        self.dropout = torch.nn.Dropout(dropout_rate)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # print(\"Start to encode...\")\n",
    "        attention_output = self.multi_head_attention(x, x, x)\n",
    "        # print(\"Get the attention output!\\n\")\n",
    "\n",
    "        # print(\"Start to feed forward...\")\n",
    "        feed_forward_input = self.norm_1(x + self.dropout(attention_output))\n",
    "        feed_forward_output = self.feed_forward(feed_forward_input)\n",
    "        output = self.norm_2(feed_forward_input + self.dropout(feed_forward_output))\n",
    "        # print(\"Get the feed forward output!\\n\")\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(torch.nn.Module):\n",
    "    def __init__(self, d_model: int, num_heads: int, num_layers: int, dropout_rate: int) -> None:\n",
    "        super(Transformer, self).__init__()\n",
    "        self.d_model = d_model\n",
    "\n",
    "        self.position_embedding = PositionEmbedding(d_model)\n",
    "        self.encoder = torch.nn.ModuleList([Encoder(d_model, num_heads, dropout_rate) for _ in range(num_layers)])\n",
    "        self.dropout = torch.nn.Dropout(dropout_rate)\n",
    "        self.prepare_output = torch.nn.Linear(SEQ_LEN * D_MODEL, 64, dtype = torch.double)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.final_layer = torch.nn.Linear(64, 1, dtype = torch.double)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.position_embedding(x)\n",
    "\n",
    "        encoder_output = x\n",
    "        for encoder in self.encoder:\n",
    "            encoder_output = encoder(encoder_output)\n",
    "\n",
    "        encoder_output = encoder_output.view(encoder_output.shape[0], -1)\n",
    "\n",
    "        # [batch_size, seq_len] -> [batch_size, 64]\n",
    "        flatten_encoder_output = self.dropout(self.prepare_output(encoder_output))\n",
    "\n",
    "        output = self.final_layer(flatten_encoder_output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model():\n",
    "    transformer = Transformer(\n",
    "        d_model = D_MODEL,\n",
    "        num_heads = NUM_HEADS,\n",
    "        num_layers = NUM_ENCODER_LAYERS,\n",
    "        dropout_rate = DROPOUT_RATE\n",
    "    ).to(device = DEVICE)\n",
    "\n",
    "    criterion = torch.nn.MSELoss().to(device = DEVICE)\n",
    "    optimizer = torch.optim.Adam(transformer.parameters(), lr = LEARNING_RATE, betas=(0.9, 0.98), eps=1e-8, weight_decay = 0.02)\n",
    "\n",
    "    return transformer, criterion, optimizer\n",
    "\n",
    "transformer, criterion, optimizer = init_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (position_embedding): PositionEmbedding(\n",
       "    (linear): Linear(in_features=17, out_features=6, bias=True)\n",
       "  )\n",
       "  (encoder): ModuleList(\n",
       "    (0-5): 6 x Encoder(\n",
       "      (multi_head_attention): MultiHeadAttention(\n",
       "        (V_linear): Linear(in_features=6, out_features=6, bias=True)\n",
       "        (K_linear): Linear(in_features=6, out_features=6, bias=True)\n",
       "        (Q_linear): Linear(in_features=6, out_features=6, bias=True)\n",
       "        (output_linear): Linear(in_features=6, out_features=6, bias=True)\n",
       "      )\n",
       "      (feed_forward): FeedForward(\n",
       "        (conv1d_1): Conv1d(6, 24, kernel_size=(1,), stride=(1,))\n",
       "        (conv1d_2): Conv1d(24, 6, kernel_size=(1,), stride=(1,))\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (norm_1): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm_2): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (prepare_output): Linear(in_features=720, out_features=64, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (final_layer): Linear(in_features=64, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device(0)\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "transformer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Train and Validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Early stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class early_stopper:\n",
    "    def __init__(self, patience: int, min_delta_percentage: float) -> None:\n",
    "        self.patience = patience\n",
    "        self.min_delta_percentage = min_delta_percentage\n",
    "        self.counter = 0\n",
    "        self.best_vloss = None\n",
    "        self.best_model_path = None\n",
    "\n",
    "    def update(self, new_best_vloss: float, model: torch.nn.Module) -> None:\n",
    "        self.counter = 0\n",
    "        self.best_vloss = new_best_vloss\n",
    "\n",
    "        if os.path.exists(self.best_model_path):\n",
    "            os.remove(self.best_model_path)\n",
    "        self.best_model_path = f'model_{datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")}.pth'\n",
    "        torch.save(model.state_dict(), self.best_model_path)\n",
    "\n",
    "    def __call__(self, vloss: float, model: torch.nn.Module) -> bool:\n",
    "        if self.best_vloss is None:\n",
    "            self.update(vloss, model)\n",
    "            return False\n",
    "\n",
    "        if vloss < self.best_vloss:\n",
    "            self.update(vloss, model)\n",
    "            return False\n",
    "        \n",
    "        elif vloss > self.best_vloss * (1 + self.min_delta_percentage):\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "            return False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classic train-validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# best_average_vloss = float('inf')\n",
    "# model_path = \"\"\n",
    "\n",
    "# for epoch in range(EPOCHS):\n",
    "#     transformer.train()\n",
    "\n",
    "#     epoch_loss = 0\n",
    "#     for x_data, y_data in tqdm(train_dataloader, desc = f'Epoch: {epoch + 1}, Training...'):\n",
    "#         x_data = x_data.to(device = DEVICE)\n",
    "#         y_data = y_data.to(device = DEVICE)\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         output = transformer(x_data)\n",
    "#         loss = criterion(output, y_data)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         epoch_loss += loss.item()\n",
    "\n",
    "#     avg_epoch_loss = epoch_loss / TXF_train.shape[0]\n",
    "#     print(f'Epoch: {epoch + 1}, Average Loss: {avg_epoch_loss}')\n",
    "#     wandb.log({'loss': epoch_loss})\n",
    "#     wandb.log({'average_loss': avg_epoch_loss})\n",
    "\n",
    "#     transformer.eval()\n",
    "#     epoch_vloss = 0\n",
    "#     with torch.no_grad():\n",
    "#         for x_data, y_data in tqdm(valid_dataloader, desc = f'Epoch: {epoch + 1}, Validating...'):\n",
    "#             x_data = x_data.to(device = DEVICE)\n",
    "#             y_data = y_data.to(device = DEVICE)\n",
    "\n",
    "#             voutput = transformer(x_data)\n",
    "#             vloss = criterion(output, y_data)\n",
    "#             epoch_vloss += vloss.item()\n",
    "    \n",
    "#     avg_epoch_vloss = epoch_vloss / TXF_valid.shape[0]\n",
    "#     print(f'Epoch: {epoch + 1}, Average Validation Loss: {avg_epoch_vloss}\\n')\n",
    "#     wandb.log({'validation_loss': epoch_vloss})\n",
    "#     wandb.log({'average_validation_loss': avg_epoch_vloss})\n",
    "\n",
    "#     if avg_epoch_vloss < best_average_vloss:\n",
    "#         if os.path.exists(model_path):\n",
    "#             os.remove(model_path)\n",
    "\n",
    "#         best_average_vloss = avg_epoch_vloss\n",
    "#         model_path = f'model_{epoch + 1}_{datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")}.pth'\n",
    "#         torch.save(transformer.state_dict(), model_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(epoch: int, model: torch.nn.Module, dataloader: torch.utils.data.DataLoader, criterion: torch.nn.Module, optimizer: torch.optim.Optimizer, device: str) -> None:\n",
    "    model.to(device = device)\n",
    "    model.train()\n",
    "\n",
    "    tloss = 0.0\n",
    "    for x_data, y_data in tqdm(dataloader, desc = f'{epoch + 1}: training...', position = 0):\n",
    "        x_data = x_data.to(device = device)\n",
    "        y_data = y_data.to(device = device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x_data)\n",
    "        loss = criterion(output, y_data)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        tloss += loss.item()\n",
    "\n",
    "    average_tloss = tloss / len(dataloader.dataset)\n",
    "    print(f'Epoch: {epoch + 1}, Average Loss: {average_tloss}')\n",
    "    wandb.log({'loss': tloss})\n",
    "    wandb.log({'average_loss': average_tloss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model(epoch: int, model: torch.nn.Module, dataloader: torch.utils.data.DataLoader, criterion: torch.nn.Module, device: str) -> float:\n",
    "    model.to(device = device)\n",
    "    model.eval()\n",
    "\n",
    "    vloss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for x_data, y_data in tqdm(dataloader, desc = f'{epoch + 1}: validating...', position = 1):\n",
    "            x_data = x_data.to(device = device)\n",
    "            y_data = y_data.to(device = device)\n",
    "\n",
    "            output = model(x_data)\n",
    "            loss = criterion(output, y_data)\n",
    "            vloss += loss.item()\n",
    "\n",
    "    average_vloss = vloss / len(dataloader.dataset)\n",
    "    print(f'Epoch: {epoch + 1}, Average Validation Loss: {average_vloss}\\n')\n",
    "    wandb.log({'validation_loss': vloss})\n",
    "    wandb.log({'average_validation_loss': average_vloss})\n",
    "\n",
    "    return average_vloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits = K, shuffle = True)\n",
    "for fold, (train_index, valid_index) in enumerate(kfold.split(train_valid_dataset)):\n",
    "    print(f'Fold: {fold + 1}')\n",
    "    \n",
    "    train_subsampler = torch.utils.data.Subset(train_valid_dataset, train_index)\n",
    "    valid_subsampler = torch.utils.data.Subset(train_valid_dataset, valid_index)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_subsampler, batch_size = BATCH_SIZE, shuffle = True, pin_memory = True, drop_last = True)\n",
    "    valid_loader = torch.utils.data.DataLoader(valid_subsampler, batch_size = BATCH_SIZE, shuffle = True, pin_memory = True, drop_last = True)\n",
    "\n",
    "    transformer, criterion, optimizer = init_model()\n",
    "    early_stop = early_stopper(patience = 5, min_delta_percentage = 0.05)\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # training loop\n",
    "    for epoch in range(EPOCHS):\n",
    "        train_model(model = transformer, dataloader = train_loader, criterion = criterion, optimizer = optimizer, device = DEVICE)\n",
    "\n",
    "        average_vloss = validate_model(model = transformer, dataloader = valid_loader, criterion = criterion, device = DEVICE)\n",
    "        if early_stop(average_vloss, transformer):\n",
    "            break\n",
    "\n",
    "    print('=' * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the best model in training and predict one of the data in test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(model_path)\n",
    "# transformer = Transformer(\n",
    "#     d_model = D_MODEL,\n",
    "#     num_heads = NUM_HEADS,\n",
    "#     num_layers = NUM_ENCODER_LAYERS,\n",
    "#     dropout_rate = DROPOUT_RATE\n",
    "# ).to(device = DEVICE)\n",
    "\n",
    "# transformer.load_state_dict(torch.load(model_path, weights_only = True))\n",
    "# transformer.eval()\n",
    "\n",
    "# test = iter(test_dataloader)\n",
    "# test_x, test_y = next(test)\n",
    "# test_output = transformer(test_x.to(device = DEVICE))\n",
    "# test_y = test_y.to(device = DEVICE)\n",
    "\n",
    "# print(f'Average difference: {torch.mean(test_output - test_y)}')\n",
    "# print(f'Minimum difference: {torch.min(abs(test_output - test_y))}')\n",
    "# print(f'Maximum difference: {torch.max(abs(test_output - test_y))}')\n",
    "# for i in range(test_output.shape[0]):\n",
    "#     print(f'Predicted: {test_output[i].item()}, \\tTrue: {test_y[i].item()}, \\tdiffernece: {test_output[i].item() - test_y[i].item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test2_path = 'data/TXFR1_1min.csv'\n",
    "# test2 = pd.read_csv(test2_path)\n",
    "# test2.index = pd.to_datetime(test2.ts)\n",
    "# test2 = test2.loc[test2.ts.between('2023-12-09', '2024-08-16')]\n",
    "\n",
    "# test2_dataset = custom_dataset(test2)\n",
    "# test2_dataloader = torch.utils.data.DataLoader(test2_dataset, batch_size = BATCH_SIZE, shuffle = False, pin_memory = True, drop_last = True)\n",
    "\n",
    "# test2 = iter(test2_dataloader)\n",
    "# test2_x, test2_y = next(test2)\n",
    "# test2_output = transformer(test2_x.to(device = DEVICE))\n",
    "# test2_y = test2_y.to(device = DEVICE)\n",
    "\n",
    "# print(f'Average difference: {torch.mean(test2_output - test2_y)}')\n",
    "# print(f'Minimum difference: {torch.min(abs(test2_output - test2_y))}')\n",
    "# print(f'Maximum difference: {torch.max(abs(test2_output - test2_y))}')\n",
    "# for i in range(test2_output.shape[0]):\n",
    "#     print(f'Predicted: {test2_output[i].item()}, \\tTrue: {test2_y[i].item()}, \\tdiffernece: {test2_output[i].item() - test2_y[i].item()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
